{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "YncRjveXeE0r",
        "outputId": "3a6b3c0b-a404-4651-f1c8-004eb5f24228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(1)\n",
        "import sys\n",
        "import sklearn\n",
        "import sklearn.ensemble\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from anchor import anchor_tabular\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import copy\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eTbxmbDbeE0t"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yscqImHSeE0u"
      },
      "outputs": [],
      "source": [
        "## 定義一個 class\n",
        "class Bunch(object):\n",
        "    \"\"\"bla\"\"\"\n",
        "    def __init__(self, adict):\n",
        "        self.__dict__.update(adict)\n",
        "dataset = Bunch({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-Lme6nBZeE0u"
      },
      "outputs": [],
      "source": [
        "# 原本的 code\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "\n",
        "df = pd.read_csv('BankChurners.csv')\n",
        "df = df[df.columns[:-2]]\n",
        "df = df.fillna(0)\n",
        "df['Attrition_Flag'] = df['Attrition_Flag'].replace({'Attrited Customer':1, 'Existing Customer':0})\n",
        "df['Gender'] = df['Gender'].replace({'M':1, 'F':0})\n",
        "df = df.drop('CLIENTNUM',axis=1)\n",
        "df = pd.get_dummies(data=df, columns=['Education_Level', 'Marital_Status', \n",
        "                                      'Income_Category', 'Card_Category']) # one-hot encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Tsl5kshgeE0v"
      },
      "outputs": [],
      "source": [
        "churn_index = df.index[df.Attrition_Flag == 1].tolist()\n",
        "non_churn_index = df.index[df.Attrition_Flag == 0].tolist()\n",
        "non_churn_index = random.sample(non_churn_index, len(churn_index)) # 讓 churn : non_churn 資料個數為 1 : 1\n",
        "new_idx = churn_index + non_churn_index\n",
        "df = df.loc[new_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QQuwCe_meE01",
        "outputId": "b10b1546-7b77-40d7-c26b-50a8b8636b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3254,)\n",
            "(3254, 36)\n"
          ]
        }
      ],
      "source": [
        "# 把原本的 pandas.DataFrame 轉成 np.array \n",
        "y = df['Attrition_Flag'].to_numpy()\n",
        "df_no_y = df.drop('Attrition_Flag', axis=1)\n",
        "x = df_no_y.to_numpy()\n",
        "print(y.shape)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "oSD-XPpmeE03",
        "outputId": "3b92e497-d68a-4203-cc56-dc981b8d32e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train 1.0\n",
            "Test 0.9416282642089093\n"
          ]
        }
      ],
      "source": [
        "# 模型預測\n",
        "c = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "c.fit(train_x, train_y)\n",
        "print('Train', sklearn.metrics.accuracy_score(train_y, c.predict(train_x)))\n",
        "print('Test', sklearn.metrics.accuracy_score(test_y, c.predict(test_x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AwLY8cHzeE03"
      },
      "outputs": [],
      "source": [
        "# 定義 anchor 中的參數\n",
        "dataset.train = train_x # 訓練資料 (numpy)\n",
        "dataset.test = test_x  # 測試資料 (numpy)\n",
        "dataset.categorical_names = {} # label encoding前的內容 (dict) \n",
        "dataset.class_names = ['Existing Customer','Attrited Customer'] # label的名稱 (list) \n",
        "dataset.feature_names = np.array(df_no_y.columns.to_list()) # feature的名稱 (numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "ShzYOjcseE04",
        "outputId": "f08c7d65-6c07-4eb8-903e-e0a99ca95fb0"
      },
      "outputs": [],
      "source": [
        "# anchor explainer \n",
        "explainer = anchor_tabular.AnchorTabularExplainer(\n",
        "    dataset.class_names,\n",
        "    dataset.feature_names,\n",
        "    dataset.train,\n",
        "    dataset.categorical_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "input 內容:\n",
        "    1. start -> 從哪一個客戶開始找 anchor\n",
        "    2. number -> 要從幾個客戶身上找 anchor\n",
        "    3. dataset -> 訓練模型時使用的 dataset\n",
        "    4. df -> 原始表格\n",
        "    5. model -> 要解釋的模型\n",
        "    6. seed -> 亂數種子(預設為1) \n",
        "\n",
        "\n",
        "重要變數:\n",
        "    1. anchors_list : 所有 anchor 集合\n",
        "    2. anchors : 做過 regular expression 的所有 anchor 集合\n",
        "    3. anchors_info : anchor 詳細資料  \n",
        "        (1) anchors 規則\n",
        "        (2) anchors 所包含的客戶數量(原本兆豐所有客戶中所包含的客戶數量)\n",
        "        (3) anchors 信心水準 \n",
        "    4. potential_customer : 潛在客戶名單\n",
        "    \n",
        "'''\n",
        "def customer_list(start, number, dataset, df, model, seed = 1):\n",
        "    \n",
        "    # 設定種子\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # 製作 Anchors 解釋器\n",
        "    explainer = anchor_tabular.AnchorTabularExplainer(\n",
        "            dataset.class_names,\n",
        "            dataset.feature_names,\n",
        "            dataset.train,\n",
        "            dataset.categorical_names)\n",
        "\n",
        "    # 變數定義\n",
        "    potential_customer = pd.DataFrame() #潛在客戶名單\n",
        "    anchors_list = [] # anchors 規則清單\n",
        "    anchors_list_confidence = [] # anchors 規則信心水準清單\n",
        "    anchors = [] # 經過 regular expression 的 anchors 規則\n",
        "    anchors_info = [] # anchors 詳細清單\n",
        "    \n",
        "    \n",
        "    \n",
        "    # 從 anchors 抓取資訊\n",
        "    current_number = 0\n",
        "    for i in dataset.test[start:]:\n",
        "        if (current_number == number):\n",
        "            break\n",
        "        if(model.predict(i.reshape(1, -1))[0]):\n",
        "            exp = explainer.explain_instance(i, model.predict, threshold=0.90)\n",
        "            anchors_list.append(exp.names()) # anchors 結果\n",
        "            anchors_list_confidence.append(exp.precision()) # anchors 精確度\n",
        "            current_number += 1\n",
        "    \n",
        "    # 將重複的 anchors 刪掉\n",
        "    temp_anchors_list = []\n",
        "    for i,j in enumerate(anchors_list):\n",
        "        if j not in temp_anchors_list:\n",
        "            temp_anchors_list.append(j)\n",
        "            anchors_info.append(\n",
        "                {\n",
        "                    \"condition\" : j,\n",
        "                    \"Quantity covered\" : 0,\n",
        "                    \"confidence interval\" : anchors_list_confidence[i]\n",
        "                }\n",
        "            ) \n",
        "    anchors_list = temp_anchors_list\n",
        "   \n",
        "    # test\n",
        "    # anchors_list = [['0 <= 我 < 1']]\n",
        "    \n",
        "    # 將規則做 regular expression 並存入 anchors 中 \n",
        "    for i in anchors_list:   \n",
        "        str_split = [re.split('( <= | >= | < | > )',j) for j in i]\n",
        "        for idx,vle in enumerate(str_split):\n",
        "            if len(vle) == 5:\n",
        "                print(vle[1])\n",
        "                vle[1] = vle[1].replace('>','<').replace('<','>')\n",
        "                print(vle[1])    \n",
        "                str_split.append(vle[2:])\n",
        "                str_split.append(vle[:3][::-1])\n",
        "                del str_split[idx]                \n",
        "        anchors.append(str_split)\n",
        "\n",
        "    \n",
        "    ## 從找到的規則中尋找潛在客戶  \n",
        "    '''\n",
        "    演算法 :\n",
        "    \n",
        "    1. 從全部的 anchors 中，取出一個 anchor，後續步驟以下分述之:\n",
        "\n",
        "        (1) 根據該 anchor 中的條件取出一個條件進行篩選，並將篩選出是否符合客戶資料之結果，放入 idx 變數中。\n",
        "        (2) 使用 idx 變數篩選符合該條件的客戶，存到 temp_df變數中。若有其他條件需要篩選 -> 回到(1)；否則則進到(3)。\n",
        "        (3) 將 temp_df 中 label 為 0 (非目前客戶)的客戶，放入潛在客戶名單。若有其他 anchor 未計算 -> 回到 1.；否則則進到 2.。 \n",
        "    \n",
        "    2. 將資料輸出，輸出內容以下分述之:\n",
        "        \n",
        "        (1) anchor 名單\n",
        "        (2) 潛在客戶名單\n",
        "    '''\n",
        "\n",
        "    for n,anchor in enumerate(anchors):\n",
        "        \n",
        "        temp_df = df \n",
        "        for i in anchor:\n",
        "            if (i[1] == ' >= '):\n",
        "                idx = temp_df.loc[:,i[0]] >= float(i[2])\n",
        "            elif (i[1] == ' <= '):\n",
        "                idx = temp_df.loc[:,i[0]] <= float(i[2])\n",
        "            elif (i[1] == ' > '):\n",
        "                idx = temp_df.loc[:,i[0]] > float(i[2])\n",
        "            elif (i[1] == ' < '):\n",
        "                idx = temp_df.loc[:,i[0]] < float(i[2])\n",
        "            else:\n",
        "                continue\n",
        "             \n",
        "            temp_df = temp_df[idx]\n",
        "            anchors_info[n]['Quantity covered'] = temp_df.shape[0]\n",
        "            \n",
        "        else: \n",
        "            idx = temp_df.loc[:,'Attrition_Flag'] == 0\n",
        "            temp_df = temp_df[idx] \n",
        "            potential_customer = pd.concat([potential_customer,temp_df], join='outer')\n",
        "            print(potential_customer.shape[0])\n",
        "\n",
        "    \n",
        "    with open(\"anchors.json\", \"w\", encoding='utf-8') as f:\n",
        "        json.dump(anchors_list, f, indent = 4)\n",
        "\n",
        "    with open(\"anchors_info.json\", \"w\", encoding='utf-8') as f:\n",
        "        json.dump(anchors_info, f, indent = 4)\n",
        "\n",
        "    potential_customer.to_excel(\"potential_customer.xlsx\")\n",
        "    \n",
        "    return(potential_customer)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\uscc_carl\\Desktop\\CSIE\\兆豐計畫\\anchor\\Anchor_churn\\projectAnchor\\customer_list.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m start \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m number \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(customer_list(start, number, dataset, df, c))\n",
            "\u001b[1;32mc:\\Users\\uscc_carl\\Desktop\\CSIE\\兆豐計畫\\anchor\\Anchor_churn\\projectAnchor\\customer_list.ipynb Cell 11\u001b[0m in \u001b[0;36mcustomer_list\u001b[1;34m(start, number, dataset, df, model, seed)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mif\u001b[39;00m(model\u001b[39m.\u001b[39mpredict(i\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))[\u001b[39m0\u001b[39m]):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     exp \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain_instance(i, model\u001b[39m.\u001b[39;49mpredict, threshold\u001b[39m=\u001b[39;49m\u001b[39m0.90\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     anchors_list\u001b[39m.\u001b[39mappend(exp\u001b[39m.\u001b[39mnames()) \u001b[39m# anchors 結果\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uscc_carl/Desktop/CSIE/%E5%85%86%E8%B1%90%E8%A8%88%E7%95%AB/anchor/Anchor_churn/projectAnchor/customer_list.ipynb#X15sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     anchors_list_confidence\u001b[39m.\u001b[39mappend(exp\u001b[39m.\u001b[39mprecision()) \u001b[39m# anchors 精確度\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_tabular.py:278\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.explain_instance\u001b[1;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m sample_fn, mapping \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sample_fn(\n\u001b[0;32m    276\u001b[0m     data_row, classifier_fn, desired_label\u001b[39m=\u001b[39mdesired_label)\n\u001b[0;32m    277\u001b[0m \u001b[39m# return sample_fn, mapping\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m exp \u001b[39m=\u001b[39m anchor_base\u001b[39m.\u001b[39mAnchorBaseBeam\u001b[39m.\u001b[39manchor_beam(\n\u001b[0;32m    279\u001b[0m     sample_fn, delta\u001b[39m=\u001b[39mdelta, epsilon\u001b[39m=\u001b[39mtau, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m    280\u001b[0m     desired_confidence\u001b[39m=\u001b[39mthreshold, max_anchor_size\u001b[39m=\u001b[39mmax_anchor_size,\n\u001b[0;32m    281\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    282\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_names_to_exp(data_row, exp, mapping)\n\u001b[0;32m    283\u001b[0m exp[\u001b[39m'\u001b[39m\u001b[39minstance\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_row\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_base.py:314\u001b[0m, in \u001b[0;36mAnchorBaseBeam.anchor_beam\u001b[1;34m(sample_fn, delta, epsilon, batch_size, min_shared_samples, desired_confidence, beam_size, verbose, epsilon_stop, min_samples_start, max_anchor_size, verbose_every, stop_on_first, coverage_samples)\u001b[0m\n\u001b[0;32m    311\u001b[0m initial_stats \u001b[39m=\u001b[39m AnchorBaseBeam\u001b[39m.\u001b[39mget_initial_statistics(tuples,\n\u001b[0;32m    312\u001b[0m                                                       state)\n\u001b[0;32m    313\u001b[0m \u001b[39m# print tuples, beam_size\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m chosen_tuples \u001b[39m=\u001b[39m AnchorBaseBeam\u001b[39m.\u001b[39;49mlucb(\n\u001b[0;32m    315\u001b[0m     sample_fns, initial_stats, epsilon, delta, batch_size,\n\u001b[0;32m    316\u001b[0m     \u001b[39mmin\u001b[39;49m(beam_size, \u001b[39mlen\u001b[39;49m(tuples)),\n\u001b[0;32m    317\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose, verbose_every\u001b[39m=\u001b[39;49mverbose_every)\n\u001b[0;32m    318\u001b[0m best_of_size[current_size] \u001b[39m=\u001b[39m [tuples[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m chosen_tuples]\n\u001b[0;32m    319\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_base.py:104\u001b[0m, in \u001b[0;36mAnchorBaseBeam.lucb\u001b[1;34m(sample_fns, initial_stats, epsilon, delta, batch_size, top_n, verbose, verbose_every)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mB = \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m B)\n\u001b[0;32m    103\u001b[0m n_samples[ut] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_size\n\u001b[1;32m--> 104\u001b[0m positives[ut] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sample_fns[ut](batch_size)\n\u001b[0;32m    105\u001b[0m means[ut] \u001b[39m=\u001b[39m positives[ut] \u001b[39m/\u001b[39m n_samples[ut]\n\u001b[0;32m    106\u001b[0m n_samples[lt] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_size\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_base.py:201\u001b[0m, in \u001b[0;36mAnchorBaseBeam.get_sample_fns.<locals>.<lambda>\u001b[1;34m(n, t)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m labels\u001b[39m.\u001b[39msum()\n\u001b[0;32m    200\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tuples:\n\u001b[1;32m--> 201\u001b[0m     sample_fns\u001b[39m.\u001b[39mappend(\u001b[39mlambda\u001b[39;00m n, t\u001b[39m=\u001b[39mt: complete_sample_fn(t, n))\n\u001b[0;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m sample_fns\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_base.py:171\u001b[0m, in \u001b[0;36mAnchorBaseBeam.get_sample_fns.<locals>.complete_sample_fn\u001b[1;34m(t, n)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplete_sample_fn\u001b[39m(t, n):\n\u001b[1;32m--> 171\u001b[0m     raw_data, data, labels \u001b[39m=\u001b[39m sample_fn(\u001b[39mlist\u001b[39;49m(t), n)\n\u001b[0;32m    172\u001b[0m     current_idx \u001b[39m=\u001b[39m state[\u001b[39m'\u001b[39m\u001b[39mcurrent_idx\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    173\u001b[0m     \u001b[39m# idxs = range(state['data'].shape[0], state['data'].shape[0] + n)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_tabular.py:265\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.get_sample_fn.<locals>.sample_fn\u001b[1;34m(present, num_samples, compute_labels)\u001b[0m\n\u001b[0;32m    263\u001b[0m labels \u001b[39m=\u001b[39m []\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m compute_labels:\n\u001b[1;32m--> 265\u001b[0m     labels \u001b[39m=\u001b[39m (predict_fn(raw_data) \u001b[39m==\u001b[39m true_label)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m raw_data, data, labels\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anchor\\anchor_tabular.py:209\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.get_sample_fn.<locals>.predict_fn\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_fn\u001b[39m(x):\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m classifier_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_fn(x))\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:832\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    812\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 832\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    834\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    835\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:885\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    880\u001b[0m all_proba \u001b[39m=\u001b[39m [\n\u001b[0;32m    881\u001b[0m     np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    882\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[0;32m    883\u001b[0m ]\n\u001b[0;32m    884\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[1;32m--> 885\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[0;32m    886\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict_proba, X, all_proba, lock)\n\u001b[0;32m    887\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[0;32m    888\u001b[0m )\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m proba \u001b[39min\u001b[39;00m all_proba:\n\u001b[0;32m    891\u001b[0m     proba \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
            "File \u001b[1;32mc:\\Users\\uscc_carl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# anchor \n",
        "start = 10\n",
        "number = 100\n",
        "print(customer_list(start, number, dataset, df, c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " <= \n",
            " >= \n",
            "[[['我', ' < ', '1'], ['我', ' >= ', '0']]]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# anchor \n",
        "start = 10\n",
        "number = 1\n",
        "print(customer_list(start, number, dataset, df, c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 2, 1]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [1,2,3,4]\n",
        "a = a[:3][::-1]\n",
        "a"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9f32e29f85dbbd0b5b72d11109c42db7aa21d3406279ecdc66ca42ae05d6c5ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
